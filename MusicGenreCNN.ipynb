{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGenreCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkGHHLhY33ZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeffb508-f38d-4bb1-b32b-16c6422bd754"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_bgkDC490bR"
      },
      "source": [
        "#import the libraries\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwEE9ys1hh47"
      },
      "source": [
        "genre_images = '/content/drive/My Drive/images_original'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9xgWw9Uyevg"
      },
      "source": [
        "Creating test and training folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fne8v_6ykN5"
      },
      "source": [
        "root_dir = genre_images \n",
        "classes_dir = ['blues', 'classical', 'country','disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "\n",
        "#creating empty training and testing folders\n",
        "for cls in classes_dir:\n",
        "    os.makedirs(root_dir +'/train/' + cls)\n",
        "    os.makedirs(root_dir +'/test/' + cls)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df5DZHimCl_w",
        "outputId": "f8467190-2692-41da-ffa8-316d04083b1a"
      },
      "source": [
        "for cls in classes_dir:\n",
        "    src = root_dir + '/' + cls # Folder to copy images from\n",
        "    allFileNames = os.listdir(src)\n",
        "    np.random.shuffle(allFileNames)\n",
        "    test_ratio = 0.25\n",
        "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
        "                                                          [int(len(allFileNames)* (1 - test_ratio))])\n",
        "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
        "    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
        "    print('Total images: ', len(allFileNames))\n",
        "    print('Training: ', len(train_FileNames))\n",
        "    print('Testing: ', len(test_FileNames))\n",
        "    for name in train_FileNames:\n",
        "      shutil.copy(name, root_dir +'/train/' + cls)\n",
        "\n",
        "    for name in test_FileNames:\n",
        "      shutil.copy(name, root_dir +'/test/' + cls)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  99\n",
            "Training:  74\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n",
            "Total images:  100\n",
            "Training:  75\n",
            "Testing:  25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-aiz1gd83tF"
      },
      "source": [
        "path1 = '/content/drive/My Drive/images_original/train'\n",
        "path2 = '/content/drive/My Drive/images_original/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO9ZEzlvRh9a",
        "outputId": "2878f257-6297-4ed6-a7f5-fc6d5371fc26"
      },
      "source": [
        "import PIL\n",
        "image = PIL.Image.open(\"hiphop00001.png\")\n",
        "image.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432, 288)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6f80l_U_X1m"
      },
      "source": [
        "img_width, img_height = 432,288\n",
        "\n",
        "train_data_dir = path1\n",
        "validation_data_dir = path2\n",
        "train_samples = 749\n",
        "test_samples = 250\n",
        "epochs = 30\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdJ1u7104KE6"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQBlvTi8BV1O",
        "outputId": "53a944ff-0cd1-4458-e8a9-40bb138f878a"
      },
      "source": [
        "#preprocessing the data\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator( rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size = (img_width, img_height), batch_size = batch_size, class_mode = 'categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 749 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUGSqb2XENAR",
        "outputId": "00636421-99be-4f33-ccd3-ce5d9e46bca9"
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size = (img_width, img_height), batch_size = batch_size, class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 250 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFbKRAMvFF0h"
      },
      "source": [
        "#define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3,3), activation = 'relu', input_shape= input_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2,4)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size= (3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,4)))\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size= (3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,4)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkudnFuHjeb"
      },
      "source": [
        "#compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics =['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwvcxSC5H5-M",
        "outputId": "6d32df8a-4320-4bc3-bc0e-47cd861038c2"
      },
      "source": [
        "#fit the model\n",
        "model.fit_generator(train_generator, steps_per_epoch=train_samples//batch_size,\n",
        "                    epochs = epochs,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps=test_samples//batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "46/46 [==============================] - 56s 1s/step - loss: 2.3490 - accuracy: 0.0965 - val_loss: 2.2952 - val_accuracy: 0.1000\n",
            "Epoch 2/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 2.2720 - accuracy: 0.1408 - val_loss: 2.0224 - val_accuracy: 0.2542\n",
            "Epoch 3/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.9770 - accuracy: 0.3113 - val_loss: 1.8373 - val_accuracy: 0.3167\n",
            "Epoch 4/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.8294 - accuracy: 0.2899 - val_loss: 1.6296 - val_accuracy: 0.4292\n",
            "Epoch 5/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.6643 - accuracy: 0.3891 - val_loss: 1.5239 - val_accuracy: 0.4958\n",
            "Epoch 6/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.5510 - accuracy: 0.4324 - val_loss: 1.7535 - val_accuracy: 0.3958\n",
            "Epoch 7/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.6123 - accuracy: 0.4094 - val_loss: 1.3907 - val_accuracy: 0.5333\n",
            "Epoch 8/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.4170 - accuracy: 0.4957 - val_loss: 1.2949 - val_accuracy: 0.5500\n",
            "Epoch 9/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.3246 - accuracy: 0.5194 - val_loss: 1.2991 - val_accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.2876 - accuracy: 0.5244 - val_loss: 1.3062 - val_accuracy: 0.4958\n",
            "Epoch 11/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.1779 - accuracy: 0.5635 - val_loss: 1.3308 - val_accuracy: 0.5500\n",
            "Epoch 12/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.1297 - accuracy: 0.5812 - val_loss: 1.2850 - val_accuracy: 0.5292\n",
            "Epoch 13/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.1229 - accuracy: 0.5817 - val_loss: 1.2684 - val_accuracy: 0.5792\n",
            "Epoch 14/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 1.0463 - accuracy: 0.6350 - val_loss: 1.2445 - val_accuracy: 0.5542\n",
            "Epoch 15/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.8709 - accuracy: 0.7045 - val_loss: 1.2969 - val_accuracy: 0.5417\n",
            "Epoch 16/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.9712 - accuracy: 0.6251 - val_loss: 1.2933 - val_accuracy: 0.5625\n",
            "Epoch 17/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.8731 - accuracy: 0.6898 - val_loss: 1.2374 - val_accuracy: 0.5792\n",
            "Epoch 18/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.6668 - accuracy: 0.7729 - val_loss: 1.3768 - val_accuracy: 0.5833\n",
            "Epoch 19/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.6701 - accuracy: 0.7458 - val_loss: 1.2191 - val_accuracy: 0.6000\n",
            "Epoch 20/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.6160 - accuracy: 0.7770 - val_loss: 1.2560 - val_accuracy: 0.5708\n",
            "Epoch 21/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.5913 - accuracy: 0.8053 - val_loss: 1.2598 - val_accuracy: 0.6042\n",
            "Epoch 22/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.4905 - accuracy: 0.8202 - val_loss: 1.4436 - val_accuracy: 0.5792\n",
            "Epoch 23/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.4416 - accuracy: 0.8561 - val_loss: 1.3294 - val_accuracy: 0.5958\n",
            "Epoch 24/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.4201 - accuracy: 0.8725 - val_loss: 1.4183 - val_accuracy: 0.6000\n",
            "Epoch 25/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.4046 - accuracy: 0.8530 - val_loss: 1.3636 - val_accuracy: 0.6125\n",
            "Epoch 26/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.3702 - accuracy: 0.8753 - val_loss: 1.5838 - val_accuracy: 0.5750\n",
            "Epoch 27/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.3724 - accuracy: 0.8607 - val_loss: 1.4593 - val_accuracy: 0.6208\n",
            "Epoch 28/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.3549 - accuracy: 0.8815 - val_loss: 1.6654 - val_accuracy: 0.5750\n",
            "Epoch 29/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.4679 - accuracy: 0.8218 - val_loss: 1.7008 - val_accuracy: 0.5708\n",
            "Epoch 30/30\n",
            "46/46 [==============================] - 55s 1s/step - loss: 0.3437 - accuracy: 0.8838 - val_loss: 1.7455 - val_accuracy: 0.5708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68d5f13f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tERgPNGwLJPZ",
        "outputId": "fb3ab989-da2a-444c-d7ed-f953748be948"
      },
      "source": [
        "predict = model.predict_classes(train_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}